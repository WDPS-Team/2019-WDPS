version: '2.2'
services:
  spark-master: 
    build:
      context: ./spark_master/
    ports:
      - 7077:7077
      - 8080:8080
  spark-worker-1:
    build:
      context: ./spark_worker/
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
  spark-submit:
    build:
      context: ./docker_submit/
    environment:
      - SPARK_APPLICATION_PYTHON_LOCATION=/app/src/spark_main.py
      - ENABLE_INIT_DAEMON=false
      - "PYSPARK_PYTHON=python3"
    volumes:
      - ./src/:/app/src/
      - ./data/:/app/data/
      - ./docker_scripts/:/docker_scripts/
    command:
      - "bash"
  es01:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.4.2
    container_name: es01
    environment:
      - node.name=es01
      - discovery.type=single-node
    volumes:
      - data01:/usr/share/elasticsearch/data
    ports:
      - 9200:9200
  trident:
    build:
     context: ./trident/
    environment:
      - KB_PORT=9090
      - KB_BIN=/app/trident/build/trident
      - KB_PATH=/data/kb/trident
    volumes:
      - ./trident-data/:/data/kb
    ports:
      - 9090:9090
volumes:
  data01:
    driver: local
  spark_submit_venv:
    driver: local
    
